{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import csv"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "raw_path='./data/'\n",
        "output_dir='./output/'\n",
        "template_dir='./templates/'\n",
        "cleaned_dir='./clean_output/'"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "template1=os.path.join(template_dir,'ant_block_1_template.csv')\n",
        "template2=os.path.join(template_dir,'ant_block_2_template.csv')\n",
        "temp_1_df=pd.read_csv(template1,dtype=str)\n",
        "temp_2_df=pd.read_csv(template2,dtype=str)\n",
        "\n",
        "r1=map(str,[0,0,800,400,400,400,400,0,400,800])\n",
        "r2=map(str,[400,800,0,800,800,400,400,800,0,0])\n",
        "\n",
        "for idx,file in enumerate([f for f in glob(os.path.join(raw_path,'*'))]):\n",
        "    try:\n",
        "        raw=pd.read_csv(file,dtype=str)\n",
        "        ant_r=raw.loc[raw['blockcode'] == 'ANT_R']\n",
        "        for subj,subj_df in ant_r.groupby(['subject']):\n",
        "            subj_df_compiled=pd.DataFrame()\n",
        "            for block, block_df in subj_df.groupby(['values.blockcount']):\n",
        "                if (block_df['values.CT_ISI'].values[0:10] == r1).all():\n",
        "                    block_df_compiled=pd.merge(block_df.reset_index(),temp_1_df,left_index=True,right_index=True,how=\"outer\")\n",
        "                else:\n",
        "                    block_df_compiled=pd.merge(block_df.reset_index(),temp_2_df,left_index=True,right_index=True,how=\"outer\")\n",
        "                subj_df_compiled=subj_df_compiled.append(block_df_compiled)\n",
        "            try:\n",
        "                subj_df_compiled.to_csv(os.path.join(output_dir, \"batchno_%s_subj_%03d.csv\"%(idx+1,int(subj))))\n",
        "            except:\n",
        "                subj_df_compiled.to_csv(os.path.join(output_dir, \"batchno_%s_subj_%s.csv\"%(idx+1,subj)))\n",
        "    except:\n",
        "        continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/cdla/Documents/scripts/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_data=[[]]\n",
        "all_data_corr=[[]]\n",
        "all_data_acc=[[]]\n",
        "for batch_csv in sorted(glob(os.path.join(output_dir,'batch*.csv'))):\n",
        "     try: \n",
        "#        print subj\n",
        "        subj=os.path.basename(batch_csv[:-4])\n",
        "        subj_df=pd.read_csv(batch_csv)\n",
        "        #Data clean up\n",
        "        date=subj_df['date'].unique()[0]\n",
        "        subjid=subj_df['subject'].unique()[0]\n",
        "        subj_df.loc[subj_df['cue_condition'].str.contains('.invalidspatial'),'cue_condition']='trial.invalid'\n",
        "        subj_df.loc[subj_df['cue_condition'].str.contains('.validspatial'),'cue_condition']='trial.validspatial'\n",
        "        subj_df.loc[subj_df['cue_condition'] == 'trial.nocue','cue_target_interval']='NaN'\n",
        "        results=pd.DataFrame()\n",
        "        \n",
        "        data=subj_df[['subject','date','location_congruence_val','flanker_congruence_val','cue_target_interval','cue_condition','latency','values.correct']]\n",
        "        data.to_csv(os.path.join(cleaned_dir,subj + '_cleaned.csv'),index=False)\n",
        "        \n",
        "        \n",
        "        cols=['subjid']+['date']\n",
        "        subj_vals=[subjid]+[date]\n",
        "        subj_vals_corr=[subjid]+[date]\n",
        "        subj_acc=[subjid]+[date]\n",
        "        \n",
        "        for bygroup,bygroup_df in subj_df.groupby(['location_congruence_val','flanker_congruence_val','cue_target_interval','cue_condition']):\n",
        "            cols.append('loc-con-%s_flank-con-%s_cue-int-%s_cue-cond-%s'%(bygroup[0],bygroup[1],bygroup[2],bygroup[3]))\n",
        "            subj_vals.append(bygroup_df['latency'].mean())\n",
        "            subj_vals_corr.append(bygroup_df.loc[bygroup_df['values.correct'] == 1,'latency'].mean())\n",
        "            subj_acc.append(bygroup_df['values.correct'].mean())\n",
        "     except:\n",
        "         print subj,\" did not work\"\n",
        "         continue        \n",
        "        \n",
        "        \n",
        "     all_data[0]=cols\n",
        "     all_data.append(subj_vals)\n",
        " \n",
        "        \n",
        "     all_data_corr[0]=cols\n",
        "     all_data_corr.append(subj_vals_corr)\n",
        "        \n",
        "     all_data_acc[0]=cols\n",
        "     all_data_acc.append(subj_acc)\n",
        "\n\n",
        "with open('ant-r_summary_latency.csv','wb') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(all_data)\n",
        "    \n",
        "with open('ant-r_summary_latency_corr.csv','wb') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(all_data_corr)\n",
        "    \n",
        "with open('ant-r_summary_acc.csv','wb') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(all_data_acc)\n",
        "\n    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batchno_2_subj_663  did not work\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "kernel_info": {
      "name": "python2"
    },
    "nteract": {
      "version": "0.8.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}