{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from shutil import copy,move\n",
    "import csv\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grading Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import collections\n",
    "from difflib import SequenceMatcher\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def grader(all_subj_data_csv, data_output_raw_csv, data_output_scored_csv,word_corr,p_r):\n",
    "\n",
    "    with open(all_subj_data_csv,'U') as file:\n",
    "        input_csv_lines_all_subj = csv.reader(file)\n",
    "        input_csv_lines_all_subj= map(list, zip(*input_csv_lines_all_subj))          \n",
    "        all_subj_csv_lines = dict((rows[0],rows[1:]) for rows in input_csv_lines_all_subj)\n",
    "\n",
    "    subj_listtype=[]\n",
    "    for idx,row in enumerate(all_subj_csv_lines['subject']):\n",
    "        if 'rey_list' in all_subj_csv_lines['trialcode'][idx]:\n",
    "            subj_listtype.append([all_subj_csv_lines['subject'][idx],all_subj_csv_lines['trialcode'][idx]])\n",
    "\n",
    "    set_subj_listtype=[]\n",
    "    for subj in subj_listtype:\n",
    "        if subj not in set_subj_listtype:\n",
    "            set_subj_listtype.append(subj)\n",
    "\n",
    "    ## count per list type\n",
    "    index_number_resp=dict()\n",
    "    for list_type in sorted([x for x in set(all_subj_csv_lines['trialcode']) if  'rey_list' in x]):\n",
    "        index_number_resp[list_type]=[]\n",
    "\n",
    "    for idx,response in enumerate(all_subj_csv_lines['response']):\n",
    "        if 'recall_response' in all_subj_csv_lines['trialcode'][idx]:\n",
    "            if 'listb' not in all_subj_csv_lines['trialcode'][idx]:\n",
    "                index_number_resp[set_subj_listtype[[x[0] for x in set_subj_listtype].index(all_subj_csv_lines['subject'][idx])][1]].append(response.lower().strip())\n",
    "            elif 'listb' in all_subj_csv_lines['trialcode'][idx]:\n",
    "                index_number_resp[set_subj_listtype[[x[0] for x in set_subj_listtype].index(all_subj_csv_lines['subject'][idx])][1][:-1]+'b'].append(response.lower().strip())\n",
    "\n",
    "    counter_dict=dict()\n",
    "    for list_type in sorted(index_number_resp.keys()):\n",
    "        rey_recall_word_count= collections.Counter(index_number_resp[list_type])\n",
    "        counter_dict[list_type]=rey_recall_word_count\n",
    "\n",
    "    total_response_for_list=dict()\n",
    "    for list_type in sorted(index_number_resp.keys()):\n",
    "        total_response_for_list[list_type]=sorted(set(index_number_resp[list_type]))\n",
    "\n",
    "    if p_r == 0:\n",
    "        rey_word_lists ={'rey_list_presentation_1a': ['drum', 'curtain', 'bell','coffee','school','parent','moon','garden',\n",
    "                                          'hat','farmer','nose','turkey', 'color', 'house', 'river'],\n",
    "\n",
    "             'rey_list_presentation_2a': ['pipe', 'wall', 'alarm', 'sugar', 'student', 'mother','star', 'painting',\n",
    "                                          'bag', 'wheat', 'mouth', 'chicken', 'sound', 'door', 'stream'],\n",
    "\n",
    "             'rey_list_presentation_3a': ['violin', 'tree', 'scarf', 'ham', 'suitcase', 'cousin', 'earth', 'stairs',\n",
    "                                          'dog', 'banana', 'town', 'radio', 'hunter', 'bucket', 'field'],\n",
    "\n",
    "             'rey_list_presentation_4a': ['doll', 'mirror', 'nail', 'sailor', 'heart', 'desert', 'face', 'letter', 'bed',\n",
    "                                         'machine', 'milk', 'helmet', 'music', 'horse', 'road'],\n",
    "             'rey_list_presentation_1b': ['desk', 'ranger','bird','shoe','stove','mountain', 'glasses', 'towel',\n",
    "                                           'cloud', 'boar','lamb','gun', 'pencil', 'church', 'fish'],\n",
    "             'rey_list_presentation_2b': ['bench', 'officer' , 'cage', 'sock','fridge','cliff', 'bottle', 'soap',\n",
    "                                         'sky', 'ship', 'goat','bullet', 'paper', 'chapel', 'crab'],\n",
    "             'rey_list_presentation_3b': ['orange', 'table', 'toad', 'corn', 'bus', 'chin', 'bleach', 'soap', 'hotel',\n",
    "                                          'donkey', 'spider', 'money', 'book', 'soldier', 'padlock'],\n",
    "             'rey_list_presentation_4b' : ['dish', 'jester', 'hill', 'coat', 'tool', 'forest', 'perfume', 'ladder',\n",
    "                                           'girl', 'foot', 'shield', 'pie', 'insect', 'ball', 'car']\n",
    "                                           }\n",
    "    elif p_r == 1:\n",
    "        rey_word_lists={'rey_list_presentation_1a': ['drum', 'curtain', 'bell','coffee','school'],\n",
    "                         'rey_list_presentation_2a': ['pipe', 'wall', 'alarm', 'sugar', 'student'],\n",
    "                         'rey_list_presentation_3a': ['violin', 'tree', 'scarf', 'ham', 'suitcase'],\n",
    "                         'rey_list_presentation_4a': ['doll', 'mirror', 'nail', 'sailor', 'heart'],\n",
    "                         'rey_list_presentation_1b': ['desk', 'ranger','bird','shoe','stove'],\n",
    "                         'rey_list_presentation_2b': ['bench', 'officer' , 'cage', 'sock','fridge'],\n",
    "                         'rey_list_presentation_3b': ['orange', 'table', 'toad', 'corn', 'bus'],\n",
    "                         'rey_list_presentation_4b' : ['dish', 'jester', 'hill', 'coat', 'tool']\n",
    "                                            }\n",
    "    elif p_r == 2:\n",
    "         rey_word_lists ={'rey_list_presentation_1a': ['nose','turkey', 'color', 'house', 'river'],\n",
    "                         'rey_list_presentation_2a': ['mouth', 'chicken', 'sound','door', 'stream'],\n",
    "                         'rey_list_presentation_3a': ['town', 'radio', 'hunter', 'bucket', 'field'],\n",
    "                         'rey_list_presentation_4a':  ['milk', 'helmet', 'music', 'horse', 'road'],\n",
    "                         'rey_list_presentation_1b':['lamb','gun', 'pencil', 'church', 'fish'],\n",
    "                         'rey_list_presentation_2b': ['goat','bullet', 'paper', 'chapel', 'crab'],\n",
    "                         'rey_list_presentation_3b': ['spider', 'money', 'book', 'soldier', 'padlock'],\n",
    "                         'rey_list_presentation_4b' : ['shield', 'pie', 'insect', 'ball', 'car']\n",
    "                                            }\n",
    "\n",
    "\n",
    "    with open(word_corr, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for word_list in sorted(total_response_for_list.keys()):\n",
    "            word_corrs=[]\n",
    "            for word in total_response_for_list[word_list]:\n",
    "                wordcorrs=[round(SequenceMatcher(None, word, x).ratio(),3) for x in rey_word_lists[word_list]]\n",
    "                word_corrs.append(wordcorrs)\n",
    "                writer.writerow([word, max(wordcorrs),rey_word_lists[word_list][wordcorrs.index(max(wordcorrs))]])\n",
    "    csvfile.close()\n",
    "\n",
    "    subj_id_list=[]\n",
    "    subj_only=[]\n",
    "    for subj in sorted(set(all_subj_csv_lines['subject'])):\n",
    "        try:\n",
    "            subj_list_type=[all_subj_csv_lines['trialcode'][x] for x in range(len(all_subj_csv_lines['subject']))\n",
    "                        if (all_subj_csv_lines['subject'][x] == subj) and ('rey_list_presentation_' in all_subj_csv_lines['trialcode'][x])][0]\n",
    "            subj_id_list.append([subj, subj_list_type])\n",
    "            subj_only.append(subj)\n",
    "        except:\n",
    "            print \"%s has an error in their data\" %subj\n",
    "            continue\n",
    "\n",
    "    full_raw_data_responses=[[all_subj_csv_lines['subject'][x],all_subj_csv_lines['trialcode'][x], all_subj_csv_lines['response'][x].lower()]\n",
    "                               for x in range(len(all_subj_csv_lines['subject']))\n",
    "                               if 'recall_response' in all_subj_csv_lines['trialcode'][x]]\n",
    "    all_responses=[]\n",
    "    repeats=[]\n",
    "    list_b_all =[]\n",
    "    list_a_all = []\n",
    "    with open(data_output_raw_csv, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow( ('subj_id', 'list_type', 'trial', 'response', 'score'))\n",
    "        for response in full_raw_data_responses:\n",
    "            subj=response[0]\n",
    "            list_to_use=[subj_id_list[x][1] for x in range(len(subj_id_list)) if subj_id_list[x][0] == subj][0]\n",
    "            list_a_all.append(list_to_use)\n",
    "            list_b=list_to_use[:-1]+'b'\n",
    "            list_b_all.append(list_b)\n",
    "            if 'listb' in response[1]:\n",
    "                if response[2] in rey_word_lists[list_b]:\n",
    "                    response.append(1)\n",
    "                else:\n",
    "                    if any(n > 0.8 for n in [SequenceMatcher(None, response[2], x).ratio() for x in rey_word_lists[list_b]]):\n",
    "                        response.append(1)\n",
    "                    else:\n",
    "                        response.append(0)\n",
    "                new_row = response[0], list_b, response[1].split('_')[0], response[2], response[3]\n",
    "            else:\n",
    "                if response[2] in rey_word_lists[list_to_use]:\n",
    "                    response.append(1)\n",
    "                else:\n",
    "                    if any(n > 0.8 for n in [SequenceMatcher(None, response[2], x).ratio() for x in rey_word_lists[list_to_use]]):\n",
    "                        response.append(1)\n",
    "                    else:\n",
    "                        response.append(0)\n",
    "                new_row = response[0], list_to_use, response[1].split('_')[0], response[2], response[3]\n",
    "            writer.writerow(new_row)\n",
    "            all_responses.append(response)\n",
    "            rep = new_row\n",
    "            repeats.append(rep)\n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "    trial_breaks=[]\n",
    "    trial_lines=[all_responses[y][1] for y in range(0,len(all_responses))]\n",
    "    trial_breaks=[i for i,x in enumerate(trial_lines[0:])\n",
    "                  if x.split('_')[0] != trial_lines[i-1].split('_')[0]]\n",
    "\n",
    "    trial_breaks=trial_breaks+[len(all_responses)]\n",
    "\n",
    "    subj_scores=[]\n",
    "    final=[]\n",
    "    final_repeats=[]\n",
    "    for idx,val in enumerate(trial_breaks[:-1]):\n",
    "            score=0\n",
    "            word_list=[]\n",
    "            for line in all_responses[trial_breaks[idx]:trial_breaks[idx+1]]:\n",
    "                if line[3] == 1:\n",
    "                    score= score + 1\n",
    "                    word_list.append(line[2])\n",
    "            test=[]\n",
    "            for idx,word in enumerate(word_list):\n",
    "                test.append([SequenceMatcher(None, word, x).ratio() for x in [y for idx2,y in enumerate(word_list) if idx != idx2]])\n",
    "            repeats=0\n",
    "            for word in test:\n",
    "                word_thresholded=[ceil(x) for x in word if x > 0.8]\n",
    "                n=sum(word_thresholded)\n",
    "                if n != 0:\n",
    "                    repeats=repeats+(((n*(n+1))-1)/(n+1))\n",
    "            subj_scores.append([line[0], line[1].split('_')[0],score,repeats])\n",
    "\n",
    "    with open(data_output_scored_csv, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['subj_id', 'list_type','listb', 'trial1', 'trial2', 'trial3', 'trial4', 'trial5', 'trial6', 'trial7',\n",
    "                         'listb_#_repeats','trial1_#_repeats', 'trial2_#_repeats', 'trial3_#_repeats', 'trial4_#_repeats',\n",
    "                         'trial5_#_repeats', 'trial6_#_repeats', 'trial7_#_repeats'])\n",
    "        subj_scores= subj_scores + ['placeholder']\n",
    "        for idx,scores in enumerate(sorted(subj_scores[:-1])):\n",
    "            scored=str(scores[2]-scores[3])\n",
    "            repeat_nm = scores[3]\n",
    "            final.append(scored)\n",
    "            final_repeats.append(repeat_nm)\n",
    "            subj_id=[scores[0]]\n",
    "            for idx2,val in enumerate(subj_id_list):\n",
    "                if subj_id[0] == subj_id_list[idx2][0]:\n",
    "                    subj_list = subj_id_list[idx2][1].split('_')[3]\n",
    "            final_row = subj_id + [subj_list] + final + final_repeats\n",
    "            if scores[0] != sorted(subj_scores)[idx+1][0]:\n",
    "                writer.writerow(final_row)\n",
    "                final_row=[]\n",
    "                subj_id=[]\n",
    "                final=[]\n",
    "                final_repeats=[]\n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#demo and age range function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "def demo_and_summary(all_subj_data_csv,demographic_data,final_summary_csv, frequency_count, subj_age_agerange_gender, sr_responses, summary_ant_scores):\n",
    "\n",
    "    with open(all_subj_data_csv,'U') as file:\n",
    "        input_csv_lines_all_subj = csv.reader(file)\n",
    "        input_csv_lines_all_subj= map(list, zip(*input_csv_lines_all_subj))\n",
    "        all_subj_csv_lines = dict((rows[0],rows[1:]) for rows in input_csv_lines_all_subj)\n",
    "\n",
    "    with open(demographic_data,'U') as file:\n",
    "        input_demo_sr_q_csv = csv.reader(file)\n",
    "        input_demo_sr_q_csv= map(list, zip(*input_demo_sr_q_csv))\n",
    "        demographic_data = dict((rows[0],rows[1:]) for rows in (input_demo_sr_q_csv))\n",
    "\n",
    "    with open(final_summary_csv,'U') as file:\n",
    "        final_summary_lines = csv.reader(file)\n",
    "        final_summary_lines= map(list, zip(*final_summary_lines))\n",
    "        rey_summary = dict((rows[0],rows[1:]) for rows in (final_summary_lines))\n",
    "\n",
    "    age_ranges = {\n",
    "        '16-19': range(16,20,1),\n",
    "        '20-29': range(20,30,1),\n",
    "        '30-39': range(30,40,1),\n",
    "        '40-49': range(40,50,1),\n",
    "        '50-59': range(50,60,1),\n",
    "        '57-69': range(57,70,1),\n",
    "        '70-79': range(70,80,1),\n",
    "        '76-89': range(76,90,1)\n",
    "                }\n",
    "    subj_id_list_demo=[]\n",
    "    subj_id_only_demo=[]\n",
    "\n",
    "    for subject in sorted(set(all_subj_csv_lines['subject'])):\n",
    "        subj_id_only_demo.append(subject)\n",
    "        subj_id_list_combined = [demographic_data['subject'][x] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subject]\n",
    "        subj_id_list_demo.append(subj_id_list_combined)\n",
    "\n",
    "    subj_id_combined=[(idx,val) for idx,val in enumerate(sorted(subj_id_only_demo))]\n",
    "\n",
    "    subj_val=[]\n",
    "    key_val_all=[]\n",
    "    for key in sorted(demographic_data.keys()):\n",
    "        for value in sorted(demographic_data[key]):\n",
    "            key_val_all.append([key,value])\n",
    "            if 'subject' in key:\n",
    "                subj_val.append(value)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    subj_id_with_index=list()\n",
    "    for subj_num in subj_val:\n",
    "        subj_combined=[[idx,val] for idx,val in enumerate(sorted(subj_id_only_demo)) if val == subj_num]\n",
    "        subj_indexvals=[[idx,val] for idx,val in enumerate(sorted(subj_id_only_demo))]\n",
    "        subj_id_with_index.append(subj_combined)\n",
    "\n",
    "\n",
    "    new_demo_dict=dict()\n",
    "    for key_var in sorted(demographic_data.keys()):\n",
    "        if 'latency' not in key_var and 'group' not in key_var and 'build' not in key_var and 'time' not in key_var and 'date' not in key_var:\n",
    "            new_demo_dict[key_var]=[]\n",
    "\n",
    "    for index1, val1 in enumerate(key_val_all):\n",
    "        if val1[0] in new_demo_dict.keys():\n",
    "            new_demo_dict[val1[0]].append(val1[1])\n",
    "\n",
    "\n",
    "    counter_demo_dict=dict()\n",
    "    for key_q in sorted(new_demo_dict.keys()):\n",
    "        answer_count=collections.Counter(new_demo_dict[key_q])\n",
    "        print answer_count\n",
    "        counter_demo_dict[key_q]=answer_count\n",
    "\n",
    "    with open(frequency_count, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['survey_question', 'response_counts'])\n",
    "        for key,value in sorted(counter_demo_dict.items()):\n",
    "            writer.writerow([key,value])\n",
    "    csvfile.close()\n",
    "\n",
    "    subj_age_gender_mem=[]\n",
    "    x=[]\n",
    "    for idx2,subj_id in enumerate(subj_id_only_demo):\n",
    "        subj_age_gen = [[demographic_data['subject'][x], demographic_data['gender_response'][x].lower(), demographic_data['age_textbox_response'][x]] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subj_id]\n",
    "        y= [[demographic_data['subject'][x]] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subj_id]\n",
    "        subj_age_gender_mem.append(subj_age_gen)\n",
    "\n",
    "\n",
    "    demo_subj_age_gender =[[demographic_data['subject'][x], demographic_data['gender_response'][x].lower(), demographic_data['age_textbox_response'][x]]\n",
    "                           for x in range(len(demographic_data['subject']))\n",
    "                           if demographic_data['subject'][x]]\n",
    "\n",
    "    raw_data_responses= [[all_subj_csv_lines['subject'][x],all_subj_csv_lines['trialcode'][x], all_subj_csv_lines['response'][x].lower()]\n",
    "                         for x in range(len(all_subj_csv_lines['subject']))\n",
    "                         if 'recall_response' in all_subj_csv_lines['trialcode'][x]]\n",
    "\n",
    "\n",
    "    key_val=[]\n",
    "    for key in age_ranges.keys():\n",
    "        for val in age_ranges[key]:\n",
    "            key_val.append([key, val])\n",
    "\n",
    "    id_age_agerange=[]\n",
    "    with open(subj_age_agerange_gender, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['subj_id', 'gender','age', 'age_range'])\n",
    "        for subj in sorted(demo_subj_age_gender):\n",
    "            subj_from_main_raw_list=[]\n",
    "            ages=subj[2]\n",
    "            gender=subj[1]\n",
    "            subj_id_raw=[val for val in raw_data_responses if val[0] == subj[0]]\n",
    "            for vals in key_val:\n",
    "                age_vals=vals[1]\n",
    "                age_vals=str(age_vals)\n",
    "                if age_vals == ages:\n",
    "                    complete_list = subj[0] + ',' + gender + \",\" + age_vals + \",\" + vals[0]\n",
    "                    id_age_agerange.append(complete_list)\n",
    "                    writer.writerow([subj[0], gender, age_vals, vals[0]])\n",
    "    csvfile.close()\n",
    "\n",
    "    subj_id_only=[]\n",
    "    for subject in sorted(set(all_subj_csv_lines['subject'])):\n",
    "        subj_id_only.append(subject)\n",
    "\n",
    "\n",
    "    subj_id_memory=[subj_mem_trials for subj_mem_trials in subj_id_only]\n",
    "\n",
    "    subj_ids_summary=[x for x in rey_summary['script.subjectid']]\n",
    "    subj_ids_summary = sorted(subj_ids_summary)\n",
    "\n",
    "    summary_key_val=[]\n",
    "    for key in sorted(rey_summary.keys()):\n",
    "        for value in sorted(rey_summary[key]):\n",
    "            summary_key_val.append([key, value])\n",
    "\n",
    "    new_summary_dict=dict()\n",
    "    for sum_key in sorted(rey_summary.keys()):\n",
    "        if 'script.starttime' not in sum_key and 'script.startdate' not in sum_key and 'script.elapsedtime' not in sum_key and 'values.trialcount' not in sum_key and 'values.completed' not in sum_key and 'values.trialcount' not in sum_key and 'parameters.min_validlatency' not in sum_key and 'computer.platform' not in sum_key:\n",
    "            new_summary_dict[sum_key]=[]\n",
    "\n",
    "\n",
    "    for sum_idx, sum_val in enumerate(summary_key_val):\n",
    "        if sum_val[0] in new_summary_dict.keys():\n",
    "            new_summary_dict[sum_val[0]].append(sum_val[1])\n",
    "\n",
    "\n",
    "    subject_summary_sr_responses= [[rey_summary['script.subjectid'][x], rey_summary['expressions.gad_7_total'][x], rey_summary['expressions.phq_total'][x],\n",
    "    rey_summary['expressions.pcl_4_total'][x], rey_summary['expressions.pcl_total_hybridscore_corrected'][x]] for x in range(len(rey_summary['script.subjectid'])) if rey_summary['values.end_survey_completed'][x] == '1']\n",
    "\n",
    "\n",
    "    subject_summary_ant_scores=[[rey_summary['script.subjectid'][x], rey_summary['expressions.overallpercentcorrect'][x], rey_summary['expressions.meanRT'][x], rey_summary['expressions.stdRT'][x]] for x in range(len(rey_summary['script.subjectid'])) if rey_summary['values.end_survey_completed'][x] == '1']\n",
    "\n",
    "    with open(sr_responses, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['subj_id', 'gad_7','phq', 'pcl_dsm4', 'pcl_hybrid'])\n",
    "        for responses in sorted(subject_summary_sr_responses):\n",
    "            writer.writerow(responses)\n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "    with open(summary_ant_scores, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['subj_id', 'percent_correct','meanRT', 'stdRT'])\n",
    "        for scores in sorted(subject_summary_ant_scores):\n",
    "            writer.writerow(scores)\n",
    "        csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "def demo_and_summary_new(all_subj_data_csv,demographic_data,subj_age_agerange_gender):\n",
    "\n",
    "    with open(all_subj_data_csv,'U') as file:\n",
    "        input_csv_lines_all_subj = csv.reader(file)\n",
    "        input_csv_lines_all_subj= map(list, zip(*input_csv_lines_all_subj))          \n",
    "        all_subj_csv_lines = dict((rows[0],rows[1:]) for rows in input_csv_lines_all_subj)\n",
    "\n",
    "    with open(demographic_data,'U') as file:\n",
    "        input_demo_sr_q_csv = csv.reader(file)\n",
    "        input_demo_sr_q_csv= map(list, zip(*input_demo_sr_q_csv))          \n",
    "        demographic_data = dict((rows[0],rows[1:]) for rows in (input_demo_sr_q_csv))\n",
    "\n",
    "\n",
    "    age_ranges = {\n",
    "        '20-29': range(20,30,1),\n",
    "        '30-39': range(30,40,1),\n",
    "        '40-49': range(40,50,1),\n",
    "        '50-59': range(50,60,1),\n",
    "        '60-69': range(60,70,1),\n",
    "        '70-90': range(70,90,1)}\n",
    "\n",
    "    subj_id_list_demo=[]\n",
    "    subj_id_only_demo=[]\n",
    "\n",
    "    for subject in sorted(set(all_subj_csv_lines['subject'])):\n",
    "        subj_id_only_demo.append(subject)\n",
    "        subj_id_list_combined = [demographic_data['subject'][x] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subject]\n",
    "        subj_id_list_demo.append(subj_id_list_combined)\n",
    "\n",
    "    subj_id_combined=[(idx,val) for idx,val in enumerate(sorted(subj_id_only_demo))]\n",
    "\n",
    "    subj_val=[]\n",
    "    key_val_all=[]\n",
    "    for key in sorted(demographic_data.keys()):\n",
    "        for value in sorted(demographic_data[key]):\n",
    "            key_val_all.append([key,value])\n",
    "            if 'subject' in key:\n",
    "                subj_val.append(value)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    subj_id_with_index=list()\n",
    "    for subj_num in subj_val:\n",
    "        subj_combined=[[idx,val] for idx,val in enumerate(sorted(subj_id_only_demo)) if val == subj_num]\n",
    "        subj_indexvals=[[idx,val] for idx,val in enumerate(sorted(subj_id_only_demo))]\n",
    "        subj_id_with_index.append(subj_combined)\n",
    "\n",
    "\n",
    "    subj_age_gender_mem=[]\n",
    "    x=[]\n",
    "    for idx2,subj_id in enumerate(subj_id_only_demo):\n",
    "        subj_age_gen = [[demographic_data['subject'][x], demographic_data['gender_response'][x].lower(), demographic_data['age_textbox_response'][x]] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subj_id]\n",
    "        y= [[demographic_data['subject'][x]] for x in range(len(demographic_data['subject'])) if demographic_data['subject'][x] == subj_id]\n",
    "        subj_age_gender_mem.append(subj_age_gen)\n",
    "\n",
    "\n",
    "    demo_subj_age_gender =[[demographic_data['subject'][x], demographic_data['gender_response'][x].lower(), demographic_data['age_textbox_response'][x]]\n",
    "                           for x in range(len(demographic_data['subject']))\n",
    "                           if demographic_data['subject'][x]]\n",
    "\n",
    "    raw_data_responses= [[all_subj_csv_lines['subject'][x],all_subj_csv_lines['trialcode'][x], all_subj_csv_lines['response'][x].lower()]\n",
    "                         for x in range(len(all_subj_csv_lines['subject']))\n",
    "                         if 'recall_response' in all_subj_csv_lines['trialcode'][x]]\n",
    "\n",
    "\n",
    "    key_val=[]\n",
    "    for key in age_ranges.keys():\n",
    "        for val in age_ranges[key]:\n",
    "            key_val.append([key, val])\n",
    "\n",
    "    id_age_agerange=[]\n",
    "    with open(subj_age_agerange_gender, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['subj_id','age', 'age_range', 'gender'])\n",
    "        for subj in sorted(demo_subj_age_gender):\n",
    "            subj_from_main_raw_list=[]\n",
    "            ages=subj[2]\n",
    "            gender=subj[1]\n",
    "            subj_id_raw=[val for val in raw_data_responses if val[0] == subj[0]]\n",
    "            for vals in key_val:\n",
    "                age_vals=vals[1]\n",
    "                age_vals=str(age_vals)\n",
    "                if age_vals == ages:\n",
    "                    complete_list = subj[0] + ',' + age_vals + \",\" + vals[0] + \",\" +  gender \n",
    "                    id_age_agerange.append(complete_list)\n",
    "                    writer.writerow([subj[0], age_vals, vals[0],gender])\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from csv import reader,writer\n",
    "\n",
    "\n",
    "def composite_scores(input_csv,output_csv):\n",
    "    scored_data = pandas.read_csv(input_csv)\n",
    "    print input_csv\n",
    "    df_trials=scored_data.loc[:,'trial1':'trial7']\n",
    "    print df_trials.columns.tolist()                              \n",
    "    composite_scores=pandas.DataFrame()\n",
    "    tmp=pandas.DataFrame()\n",
    "    composite_scores['total_learning']=df_trials[['trial1', 'trial2', 'trial3', 'trial4', 'trial5']].apply(lambda row: np.sum(row),axis=1)\n",
    "    tmp['test']=df_trials['trial1'].tolist()*5\n",
    "    composite_scores['corrected_total_learning']=composite_scores['total_learning'].subtract(tmp['test'])\n",
    "\n",
    "    composite_scores['learning_rate']=df_trials['trial5'].subtract(df_trials['trial1'],axis='rows')\n",
    "    composite_scores['proactive_interference']=df_trials['trial1'].subtract(scored_data['listb'],axis='rows')\n",
    "    composite_scores['retroactive_interference']=df_trials['trial5'].subtract(df_trials['trial6'],axis='rows')\n",
    "\n",
    "    composite_scores['forgetting_and_retention']=df_trials['trial5'].subtract(df_trials['trial7'],axis='rows')\n",
    "\n",
    "    composite_scores_transposed=composite_scores.transpose()\n",
    "\n",
    "    composite_scores_transposed.to_csv(output_csv,header=True,index=['measure','score'])\n",
    "    composite_scores.to_csv(output_csv,header=True,index=['measure','score'])\n",
    "\n",
    "# for scored in  glob('/Users/lillyel-said/Desktop/vmreact/output/*_scored_data.csv'):\n",
    "#     composite_scores(scored,scored.replace('_scored_data.csv','_composite_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lillyel-said/Desktop/data_transfer/best_1001_tp1_inquisit/csv/best_1001_tp1_summary.csv\n",
      "Counter({'0': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'33': 1})\n",
      "Counter({\"Associate's degree\": 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Hispanic or Latino (a person of Cuban, Mexican, Puerto Rican, Cuban, South or Central American, or other Spanish culture or origin, regardless of race)': 1})\n",
      "Counter({'Male': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'American Indian or Alaska Native (a person having origins in any of the original peoples of North and South America (including Central America) who maintains cultural identification through tribal affiliation or community attachment)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1001': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1002_tp1_inquisit/csv/best_1002_tp1_summary.csv\n",
      "Counter({'1': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'69': 1})\n",
      "Counter({'Some college, no degree': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Not Hispanic or Latino': 1})\n",
      "Counter({'Male': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1002': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1003_tp1_inquisit/csv/best_1003_tp1_summary.csv\n",
      "Counter({'2': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'55': 1})\n",
      "Counter({'Postsecondary non-degree award': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Hispanic or Latino (a person of Cuban, Mexican, Puerto Rican, Cuban, South or Central American, or other Spanish culture or origin, regardless of race)': 1})\n",
      "Counter({'Male': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1003': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1004_tp1_inquisit/csv/best_1004_tp1_summary.csv\n",
      "Counter({'3': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'74': 1})\n",
      "Counter({\"Bachelor's degree\": 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Not Hispanic or Latino': 1})\n",
      "Counter({'Male': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1004': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1005_tp1_inquisit/csv/best_1005_tp1_summary.csv\n",
      "Counter({'5': 1, '4': 1})\n",
      "Counter({'': 2})\n",
      "Counter({'77': 2})\n",
      "Counter({'Some college, no degree': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'Not Hispanic or Latino': 2})\n",
      "Counter({'Male': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'Yes': 2})\n",
      "Counter({'American Indian or Alaska Native (a person having origins in any of the original peoples of North and South America (including Central America) who maintains cultural identification through tribal affiliation or community attachment)': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 2})\n",
      "Counter({'': 2})\n",
      "Counter({'1005': 2})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1006_tp1_inquisit/csv/best_1006_tp1_summary.csv\n",
      "Counter({'6': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'29': 1})\n",
      "Counter({'High school diploma or equivalent': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Not Hispanic or Latino': 1})\n",
      "Counter({'Male': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1006': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1007_tp1_inquisit/csv/best_1007_tp1_summary.csv\n",
      "Counter({'7': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'28': 1})\n",
      "Counter({\"Bachelor's degree\": 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Hispanic or Latino (a person of Cuban, Mexican, Puerto Rican, Cuban, South or Central American, or other Spanish culture or origin, regardless of race)': 1})\n",
      "Counter({'Female': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'Yes': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'White (a person having origins in any of the original peoples of Europe, the Middle East, or North Africa)': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'West - AK, CA, CO, HI, ID, MT, NV, OR, UT, WA, WY': 1})\n",
      "Counter({'': 1})\n",
      "Counter({'1007': 1})\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1008_tp1_inquisit/csv/best_1008_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1009_tp1_inquisit/csv/best_1009_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1010_tp1_inquisit/csv/best_1010_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1011_tp1_inquisit/csv/best_1011_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1012_tp1_inquisit/csv/best_1012_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1013_tp1_inquisit/csv/best_1013_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1014_tp1_inquisit/csv/best_1014_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1015_tp1_inquisit/csv/best_1015_tp1_summary.csv\n",
      "/Users/lillyel-said/Desktop/data_transfer/best_1016_tp1_inquisit/csv/best_1016_tp1_summary.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-98e81769a0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdemo_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/lillyel-said/Desktop/data_transfer/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*demographics_survey.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msummary_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/lillyel-said/Desktop/data_transfer/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*summary.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0msummary_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#     grader(all_subj_data_csv, os.path.join(dir,'parsed_raw_data' + '_'+ date + '.csv'),os.path.join(dir,'scored_data' + '_'+ date + '.csv'),os.path.join(dir,'word_correlations' + '_'+ date + '.csv'),0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#     grader(all_subj_data_csv,os.path.join(dir,'parsed_raw_data_primacy'+ '_'+ date + '.csv'),os.path.join(dir,'scored_data_primacy'+ '_'+ date + '.csv'),os.path.join(dir,'word_correlations_primacy'+ '_'+ date + '.csv'),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import collections\n",
    "from difflib import SequenceMatcher\n",
    "from math import ceil\n",
    "\n",
    "format = \"%Y_%m_%d\"\n",
    "current_date=datetime.datetime.today()\n",
    "date = current_date.strftime(format)\n",
    "\n",
    "\n",
    "output='/Users/lillyel-said/Desktop/data_transfer/demo'\n",
    "os.chdir('/Users/lillyel-said/Desktop/stanford/scripts/inquisit/final/grader_inq_to_edit')\n",
    "\n",
    "for raw in glob(os.path.join(output,'*raw.csv')):\n",
    "    all_subj_data_csv=raw\n",
    "    path=raw.split('/')[-1]\n",
    "    path=path.split('_')[0:3]\n",
    "    id='_'.join(path)+'_inquisit'\n",
    "    dir=os.path.join('/Users/lillyel-said/Desktop/data_transfer/',id,'out')\n",
    "    demo_data=glob(os.path.join('/Users/lillyel-said/Desktop/data_transfer/',id,'csv','*demographics_survey.csv'))\n",
    "    summary_data=glob(os.path.join('/Users/lillyel-said/Desktop/data_transfer/',id,'csv','*summary.csv'))\n",
    "    print summary_data[0]\n",
    "    #     grader(all_subj_data_csv, os.path.join(dir,'parsed_raw_data' + '_'+ date + '.csv'),os.path.join(dir,'scored_data' + '_'+ date + '.csv'),os.path.join(dir,'word_correlations' + '_'+ date + '.csv'),0)\n",
    "    #     grader(all_subj_data_csv,os.path.join(dir,'parsed_raw_data_primacy'+ '_'+ date + '.csv'),os.path.join(dir,'scored_data_primacy'+ '_'+ date + '.csv'),os.path.join(dir,'word_correlations_primacy'+ '_'+ date + '.csv'),1)\n",
    "    #     grader(all_subj_data_csv,os.path.join(dir,'parsed_raw_data_recency'+ '_'+ date + '.csv'),os.path.join(dir,'scored_data_recency'+ '_'+ date + '.csv'),os.path.join(dir,'word_correlations_recency'+ '_'+ date + '.csv'),2)\n",
    "#         composite_scores(os.path.join(dir,'scored_data' + '_'+ date + '.csv'),os.path.join(dir,'composite_scores_vakil'+ '_'+ date + '.csv'))\n",
    "    try:\n",
    "        demo_and_summary(all_subj_data_csv, demo_data[0], summary_data[0], os.path.join(dir, 'frequency_counts'+ '_'+ date + '.csv'),os.path.join(dir,'subj_age_agerange_gender'+ '_'+ date + '.csv'), os.path.join(dir, 'sr_responses'+ '_'+ date + '.csv'), os.path.join(dir, 'summary_ant_scores'+ '_'+ date + '.csv'))\n",
    "        demo_and_summary_new(all_subj_data_csv, demo_data[0],os.path.join(dir, 'subj_age_agerange_gender_new_age_bins'+ '_'+ date + '.csv'),)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# format = \"%Y_%m_%d\"\n",
    "# current_date=datetime.datetime.today()\n",
    "# date = current_date.strftime(format)\n",
    "\n",
    "# output_csv_location='/Users/cdla/Desktop/scratch/vmreact/2_vmreact/'\n",
    "\n",
    "# for raw in  glob('/Users/cdla/Desktop/scratch/vmreact/1_rawdata/*/*raw.csv'):\n",
    "#     raw_data=raw\n",
    "#     demo_data=raw.replace('raw.csv','demo.csv')\n",
    "#     summary_data=raw.replace('raw.csv','summary.csv')\n",
    "#     prefix='mturk_'+ os.path.basename(os.path.dirname(raw_data)).split('_')[1] + '_'\n",
    "#     grader(raw_data, os.path.join(output_csv_location,prefix + 'parsed_raw_data.csv'),os.path.join(output_csv_location,prefix + 'scored_data.csv'),os.path.join(output_csv_location,prefix + 'word_correlations.csv'),0)\n",
    "#     grader(raw_data,os.path.join(output_csv_location,prefix + 'parsed_raw_data_primacy.csv'),os.path.join(output_csv_location,prefix + 'scored_data_primacy.csv'),os.path.join(output_csv_location,prefix + 'word_correlations_primacy.csv'),1)\n",
    "#     grader(raw_data,os.path.join(output_csv_location,prefix + 'parsed_raw_data_recency.csv'),os.path.join(output_csv_location,prefix + 'scored_data_recency.csv'),os.path.join(output_csv_location,prefix + 'word_correlations_recency.csv'),2)\n",
    "#     copy(demo_data,os.path.join(output_csv_location, prefix + 'demo.csv'))\n",
    "#     copy(summary_data,os.path.join(output_csv_location, prefix + 'summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "scored_dir='/Users/lillyel-said/Desktop/vmreact/output/'\n",
    "for scored_csv in glob(os.path.join(scored_dir,'*scored*')):\n",
    "    with open(scored_csv,'U') as source:\n",
    "        rdr = csv.reader(source)\n",
    "        with open(os.path.join(scored_dir,'tmp.csv'),'wb') as result:\n",
    "            wtr = csv.writer(result)\n",
    "            for r in rdr:\n",
    "                wtr.writerow(r[0:18])\n",
    "    move(os.path.join(scored_dir,'tmp.csv'),scored_csv)\n",
    "    print scored_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# Getting composite scores from scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "scored_dir='/Users/lillyel-said/Desktop/vmreact/output/'\n",
    "\n",
    "demo_cols=[]\n",
    "clin_raw_cols=[]\n",
    "sum_cols=['script.startdate', 'script.starttime', 'subject',\n",
    "          'expressions.gad_7_total', 'expressions.phq_total', 'expressions.pcl_4_total',\n",
    "          'expressions.pcl_total_hybridscore_corrected', 'expressions.pcl_total_hybridscore_uncorrected']\n",
    "scored_cols=['subj_id', 'list_type', 'listb', 'trial1', 'trial2', 'trial3',\n",
    "              'trial4', 'trial5', 'trial6', 'trial7', 'listb_#_repeats', 'trial1_#_repeats', 'trial2_#_repeats',\n",
    "              'trial3_#_repeats', 'trial4_#_repeats', 'trial5_#_repeats', 'trial6_#_repeats', 'trial7_#_repeats']\n",
    "composite_cols=['subject', 'total_learning', 'corrected_total_learning', 'learning_rate',\n",
    "                 'proactive_interference', 'retroactive_interference', 'forgetting_and_retention']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "age_range_gender_cols=['age_range']\n",
    "\n",
    "for batch in range(1,9):\n",
    "    batch=str(batch)\n",
    "    demo=os.path.join(scored_dir,'mturk_batch'+batch+'_demo.csv')\n",
    "    clin_raw=os.path.join(scored_dir,'mturk_batch'+batch+'_end.csv')\n",
    "    summ=os.path.join(scored_dir,'mturk_batch'+batch+'_summary.csv')\n",
    "    scored=os.path.join(scored_dir,'mturk_batch'+batch+'_scored_data.csv')\n",
    "    composite=os.path.join(scored_dir,'mturk_batch'+batch+'_composite_scores.csv')\n",
    "    age_range_gender_csv=os.path.join(scored_dir,'mturk_batch'+batch+'_age_range_gender.csv')\n",
    "\n",
    "    demo_df=pd.read_csv(demo,dtype=str)\n",
    "#     demo_cols.extend([x for x in demo_df.columns.tolist() if ('latency' not in x and 'online' not in x and 'Unnamed' not in x and 'time_comp' not in x and 'subj_id' not in x)])\n",
    "    demo_cols.extend([x for x in demo_df.columns.tolist() if ('latency' not in x and 'Unnamed' not in x and 'subj_id' not in x and 'age_textbox')])\n",
    "    print batch\n",
    "    age_range_df=pd.read_csv(age_range_gender_csv)\n",
    "    age_range_gender_cols.extend([x for x in age_range_df.columns.tolist() if ('age' not in x and 'subj_id' not in x and 'gender' not in x)])\n",
    "    clin_raw_df=pd.read_csv(clin_raw,dtype=str)\n",
    "    clin_raw_cols.extend([x for x in clin_raw_df.columns.tolist() if 'latency' not in x and 'end' not in x and 'Unnamed' not in x])\n",
    "    sum_df=pd.read_csv(summ,dtype=str)\n",
    "    scored_df=pd.read_csv(scored,dtype=str)\n",
    "    comp_df=pd.read_csv(composite,dtype=str).rename(index=str,columns={'Unnamed: 0':'subject'})\n",
    "    age_range_gender=pd.read_csv(age_range_gender_csv,dtype=str)\n",
    "\n",
    "demo_cols=list(set(demo_cols))\n",
    "clin_raw_cols=list(set(clin_raw_cols))    \n",
    "    \n",
    "print demo_cols\n",
    "print clin_raw_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to get latency values,\n",
    "use the scored to set the subject ids. \n",
    "append composite to scored_cols since they're in the same order and composite doesn't have subject ids\n",
    "summary - use script.subjectid\n",
    "demo - use subject\n",
    "clin_raw - use subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "scored_dir='/Users/lillyel-said/Desktop/vmreact/vmreact/2_vmreact/'\n",
    "latency_csv=os.path.join(scored_dir,'vmreact_latency_summary.csv')\n",
    "\n",
    "\n",
    "for batch in range(1,9):\n",
    "# for batch in [8]:\n",
    "    batch_df=pd.DataFrame()\n",
    "    batch=str(batch)\n",
    "    print 'mturk_batch' + batch\n",
    "    \n",
    "    demo=os.path.join(scored_dir,'mturk_batch'+batch+'_demo.csv')\n",
    "    clin_raw=os.path.join(scored_dir,'mturk_batch'+batch+'_end.csv')\n",
    "    sum=os.path.join(scored_dir,'mturk_batch'+batch+'_summary.csv')\n",
    "    scored=os.path.join(scored_dir,'mturk_batch'+batch+'_scored_data.csv')\n",
    "    primacy=os.path.join(scored_dir,'mturk_batch'+batch+'_scored_data_primacy.csv')\n",
    "    recency=os.path.join(scored_dir,'mturk_batch'+batch+'_scored_data_recency.csv')\n",
    "    composite=os.path.join(scored_dir,'mturk_batch'+batch+'_composite_scores.csv')\n",
    "\n",
    "    demo_df=pd.read_csv(demo,dtype=str)\n",
    "    clin_raw_df=pd.read_csv(clin_raw,dtype=str)\n",
    "    sum_df=pd.read_csv(sum,dtype=str).rename(index=str,columns={'script.subjectid': 'subject'})\n",
    "    scored_df=pd.read_csv(scored)\n",
    "    \n",
    "    primacy_df=pd.read_csv(primacy,dtype=str)\n",
    "    recency_df=pd.read_csv(recency,dtype=str)\n",
    "\n",
    "    extra_measures= primacy_df.merge(recency_df,on='subj_id',left_index=True,how='left',suffixes=('_primacy','_recency')).rename(columns={'subj_id':'subject'})    \n",
    "    comp_df=pd.read_csv(composite).rename(index=str,columns={'Unnamed: 0':'subject'})\n",
    "    comp_df['subject']=comp_df['subject'].apply(int)\n",
    "        \n",
    "    vmreact_df=pd.merge(scored_df,comp_df,left_index=True,right_on='subject',how='left').drop('subject',axis=1)\n",
    "    vmreact_df['subj_id']=vmreact_df['subj_id'].astype(str)\n",
    "    \n",
    "    #vmreact_df['subj_id']=vmreact_df['subj_id'].apply(pd.to_numeric)\n",
    "    latency_df=pd.read_csv(latency_csv,dtype=str)\n",
    "    latency_df=latency_df.drop_duplicates().reset_index()\n",
    "    \n",
    "    subject_ids=vmreact_df['subj_id'].tolist()\n",
    "                         \n",
    "    vmreact_df=vmreact_df.merge(extra_measures,left_on='subj_id',right_on='subject').drop('subject',axis=1)\n",
    "\n",
    "\n",
    "    batch_demo_cols=[x for x in demo_df.columns.tolist() if x in demo_cols]\n",
    "    append_demo_cols=[x for x in demo_cols if x not in demo_df.columns.tolist()]\n",
    "    demo_df=demo_df[demo_df['subject'].astype(str).isin(subject_ids)][batch_demo_cols]\n",
    "    \n",
    "    for col in append_demo_cols:\n",
    "        demo_df[col]=np.nan\n",
    "#     print demo_df\n",
    "#     demo_df['subject']=demo_df['subject'].apply(pd.to_numeric)\n",
    "\n",
    "    batch_clin_cols=[x for x in clin_raw_df.columns.tolist() if x in clin_raw_cols]\n",
    "    append_clin_cols=[x for x in clin_raw_cols if x not in clin_raw_df.columns.tolist()]\n",
    "    clin_raw_df=clin_raw_df[clin_raw_df['subject'].astype(str).isin(subject_ids)][batch_clin_cols]\n",
    "    for col in sorted(append_clin_cols):\n",
    "        clin_raw_df[col]=np.nan\n",
    "    #clin_raw_df['subject']=clin_raw_df['subject'].apply(pd.to_numeric)\n",
    "\n",
    "    batch_sum_cols=[x for x in sum_df.columns.tolist() if x in sum_cols]\n",
    "    append_sum_cols=[x for x in sum_cols if x not in sum_df.columns.tolist()]\n",
    "    sum_df=sum_df[sum_df['subject'].astype(str).isin(subject_ids)][batch_sum_cols]\n",
    "    for col in sorted(append_sum_cols):\n",
    "        sum_df[col]=np.nan   \n",
    "    #sum_df['subject']=sum_df['subject'].apply(pd.to_numeric)\n",
    "    \n",
    "    batch_df=demo_df.merge(sum_df,left_on='subject',right_on='subject').drop(['script.startdate','script.starttime'],axis=1)\n",
    "    batch_df=batch_df.merge(clin_raw_df,left_on='subject',right_on='subject').drop(['date_y','time_y','group_y','build_y'],axis=1)\n",
    "    batch_df=batch_df.merge(vmreact_df,left_on='subject', right_on='subj_id').drop('subj_id',axis=1)\n",
    "    batch_df=batch_df.rename(columns={'date_x':'date','time_x':'time','group_x':'group','build_x':'build'})\n",
    "    #print batch_df\n",
    "    \n",
    "    print subject_ids\n",
    "    latency_df['subjid']=latency_df['subjid'].astype(str)\n",
    "    latency_df['date']=latency_df['date'].astype(int)\n",
    "    batch_df['date']=batch_df['date'].astype(int)\n",
    "                \n",
    "    latency_df=latency_df.loc[(latency_df['subjid'].isin(batch_df['subject'].astype(str).tolist()))] # & latency_df['date'].isin(batch_df['date'].tolist()))]\n",
    "    \n",
    "    latency_df=latency_df.loc[(latency_df['subjid'].isin(batch_df['subject'].astype(str).tolist()) & latency_df['date'].isin(batch_df['date'].tolist()))]\n",
    "    \n",
    "    batch_df['subject']=batch_df['subject'].astype(str)\n",
    "    batch_df=batch_df.merge(latency_df,left_on='subject',right_on='subjid')\n",
    "    \n",
    "    batch_df.to_csv(os.path.join(scored_dir,'mturk_batch' +batch+'_compiled.csv'))\n",
    "#     os.system('open /Users/cdla/Desktop/scratch/vmreact/2_vmreact/'+'mturk_batch'+batch+'_compiled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "dataframes_to_concat=[]\n",
    "result=[]\n",
    "for compiled_csv in glob(os.path.join(scored_dir,'*compiled.csv')):\n",
    "    df=pd.read_csv(compiled_csv,dtype=str)\n",
    "    dataframes_to_concat.append(df)\n",
    "\n",
    "\n",
    "result=pd.concat(dataframes_to_concat).reindex_axis(df.columns.tolist(),axis=1).drop(['index','date_y','subjid','Unnamed: 0'],axis=1).dropna(how='all',axis=1).drop_duplicates()\n",
    "\n",
    "#print result.subject\n",
    "result=result[~result.subject.isin(['XXX','AVD6HMIO1HLFI','A5EU1AQJNC7F2'])]\n",
    "result.drop_duplicates(['date_x','subject'], inplace=True)\n",
    "display(result)\n",
    "result=result.drop_duplicates()\n",
    "result.to_csv(os.path.join(scored_dir,'mturk_vmreact_complete_compilation.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python2",
   "language": "python",
   "display_name": "Python 2"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "name": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12",
   "file_extension": ".py",
   "codemirror_mode": {
    "version": 2,
    "name": "ipython"
   }
  },
  "kernel_info": {
   "name": "python2"
  },
  "nteract": {
   "version": "0.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
